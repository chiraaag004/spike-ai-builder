# üöÄ AI Agent Orchestrator for SEO & Analytics

**A Multi-Agent System that fuses Google Analytics 4 (GA4) traffic data with Technical SEO intelligence.**

This project is a high-performance AI backend built with **FastAPI**, **Pandas**, and **LLMs (LiteLLM)**. It features an intelligent Orchestrator that routes user queries to specialized agents, executes complex data fusion (SQL-style joins) between live APIs and static datasets, and handles large-scale data analysis with auto-profiling.

---

## üìÇ Project Structure

```text
spike-ai-builder/
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ analytics_agent.py   # GA4 API Handler (Tier 1 Logic & Smart Retry)
‚îÇ   ‚îú‚îÄ‚îÄ seo_agent.py         # Google Sheets Handler (Tier 2 Logic & Profiling)
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ llm_client.py        # LiteLLM Wrapper with Exponential Backoff
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py           # System Prompts, Routing Rules & Guardrails
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ main.py                  # FastAPI Entry Point
‚îú‚îÄ‚îÄ orchestrator.py          # The "Brain" (Intent Routing & Multi-Agent Fusion)
‚îú‚îÄ‚îÄ deploy.sh                # Production Deployment Script (Linux)
‚îú‚îÄ‚îÄ deploy_windows.ps1       # Local Development Script (Windows)
‚îú‚îÄ‚îÄ seed_ga4_data.py         # GA4 Backfill Script ("Resourcefulness" Challenge)
‚îú‚îÄ‚îÄ test.py                  # Automated Test Suite (Tiers 1, 2, 3)
‚îú‚îÄ‚îÄ requirements.txt         # Project Dependencies
‚îú‚îÄ‚îÄ .env                     # API Keys (Not tracked in git)
‚îú‚îÄ‚îÄ .gitignore               # Ignorelist
‚îú‚îÄ‚îÄ credentials.json         # Google Service Account Key (Not tracked in git)
‚îî‚îÄ‚îÄ README.md                # Documentation
```

---

## üèÜ Hackathon Deliverables Achieved

| Feature | Status | Description |
| :--- | :---: | :--- |
| **Tier 1: Intelligent Routing** | ‚úÖ | Automatically detects if a query needs GA4, SEO, or BOTH. Routes to the correct Agent and specific Sheet Tab. |
| **Tier 2: Deep Analysis** | ‚úÖ | Performs advanced Pandas filtering (`Indexability`, `Status Code`) and auto-profiles data (Counts & Breakdowns) before summarizing. |
| **Tier 3: Multi-Agent Fusion** | ‚úÖ | **The "Flagship" Feature.** Fetches live traffic from GA4, joins it with Technical SEO data (Titles, Meta) by normalizing URLs, and delivers a unified insight. |
| **Resourcefulness** | ‚úÖ | Includes `seed_ga4_data.py` to backfill data into GA4 via Measurement Protocol (bypassing the need for a live website). |

---

## üèóÔ∏è Architecture

The system follows a **Hub-and-Spoke** architecture:

1.  **The Orchestrator:** The "Brain" that parses intent and manages the workflow.
2.  **Analytics Agent (GA4):** Connects to Google Analytics Data API. Includes "Smart Retry" logic for invalid metrics.
3.  **SEO Agent (Sheets):** Connects to Google Sheets (Screaming Frog exports). Includes "Fuzzy Column Matching" and "Auto-Type Conversion".
4.  **Fusion Layer:** A Pandas-based logic block that normalizes URLs (stripping protocols/trailing slashes) to merge dataset A and B.

```mermaid
graph TD
    User[User Query] --> API[FastAPI Server]
    API --> Orch[Orchestrator]
    
    %% Routing Logic
    Orch -->|Intent: GA4| GA4_Agent[Analytics Agent]
    Orch -->|Intent: SEO| SEO_Agent[SEO Agent]
    Orch -->|Intent: BOTH| Fusion[Fusion Layer]
    
    %% Data Sources
    GA4_Agent <-->|Google Analytics Data API| Google[Google Cloud]
    SEO_Agent <-->|Pandas Read| CSV[Google Sheets / CSV]
    
    %% Fusion Logic
    Fusion -->|Fetch Metrics| GA4_Agent
    Fusion -->|Fetch Metadata| SEO_Agent
    Fusion -->|Normalize & Join| PandasEngine[Pandas Merge Engine]
    
    %% Output
    GA4_Agent --> Response
    SEO_Agent --> Response
    PandasEngine --> Response
    Response --> User
---

## üõ†Ô∏è Setup & Installation

### 1. Prerequisites
* Python 3.10+
* A Google Cloud Service Account (`credentials.json`) with access to GA4 and Sheets.
* An LLM Provider Key (LiteLLM/OpenAI/Gemini).

### 2. Installation
Clone the repository and install dependencies:

```bash
# Windows
python -m venv .venv
.\.venv\Scripts\Activate
pip install -r requirements.txt

# Linux / Mac
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

```

### 3. Configuration

Create a `.env` file in the root directory:

```ini
LITELLM_API_KEY=sk-your-key-here
SEO_SPREADSHEET_ID=your-sheet-id-here

```

Ensure `credentials.json` is placed in the **root** folder.

---

## üöÄ How to Run

### **Option A: Production / Evaluator (Linux)**

Use the provided deployment script which handles environment creation and `pip` issues automatically:

```bash
bash deploy.sh

```

*Server will start on port 8080 in background mode.*

### **Option B: Local Development (Windows)**

```powershell
.\deploy_windows.ps1

```

*Or manually:* `uvicorn main:app --host 0.0.0.0 --port 8080 --reload`

---

## üß™ Testing the Agents

You can use the included `test.py` script to verify all 3 Tiers.

```bash
python test.py

```

### **Sample Queries Supported**

**1. Analytics (Tier 1)**

> *"How many active users did we have in the last 7 days?"*

**2. Technical SEO (Tier 2)**

> *"Show me all pages with 404 errors."*
> *"Group pages by Indexability and give me a count."* (Uses Auto-Profiling)

**3. Fusion (Tier 3 - High Value)**

> *"What are the top 5 pages by views and what are their title tags?"*
> *(This triggers the Multi-Agent Merge logic)*

---

## üí° "Resourcefulness" Challenge

**Goal:** Ingest data into GA4 without a live website.

I solved this by building **`seed_ga4_data.py`**.

* It uses the **GA4 Measurement Protocol API**.
* It generates synthetic traffic events.
* It sends them directly to Google's servers via HTTP POST, bypassing the browser.

**To run the backfill:**

```bash
python seed_ga4_data.py

```

*(Note: Data appears in "Realtime" dashboard instantly, but standard API takes 24-48h to process).*

---

## üõ°Ô∏è Robustness & Optimizations

* **Exponential Backoff:** The LLM Client handles rate limits (429 errors) by waiting 2s, 4s, 8s...
* **Smart Truncation:** Large text fields (like HTML content) are truncated to 100 chars to prevent Token Limit Exceeded errors.
* **URL Normalization:** The Fusion engine strips `https://`, `www.`, and trailing slashes (`/`) to ensure `site.com/blog` matches `/blog/`.
* **Safe Defaults:** If the LLM requests an invalid metric (e.g. `bounce_rate`), the Analytics Agent catches the 400 error and retries with standard metrics automatically.

---

## üë• Authors

* **Chirag Gupta**
* **Kumar Ayush Aman**